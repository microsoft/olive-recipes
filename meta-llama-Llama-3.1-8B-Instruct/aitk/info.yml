keywords:
    aitk
arch: llama3
recipes:
    - file: "llama3_1_qnn_config.json"
      device: npu
      ep: QNNExecutionProvider
      aitk:
        oliveFile: "phi3_5/qnn_config.json"
    - file: "llama3_1_vitis_ai_config.json"
      device: npu
      ep: VitisAIExecutionProvider
      aitk:
        oliveFile: "phi3_5/qdq_config_vitis_ai.json"
        requirementsPatches:
          - AutoGptq
        runtimeOverwrite:
          executeEp: CUDAExecutionProvider
        evalRuntime: AMDNPU
    - file: "llama3_1_ov_config.json"
      devices:
        - npu
      ep: OpenVINOExecutionProvider
    - file: "llama3_1_ov_gpu_config.json"
      devices:
        - cpu
        - gpu
      ep: OpenVINOExecutionProvider
    - file: "llama3_1_trtrtx_config.json"
      device: gpu
      ep: NvTensorRTRTXExecutionProvider
    - file: "llama3_1_dml_config.json"
      device: gpu
      ep: DmlExecutionProvider
aitk:
    modelInfo:
        id: "huggingface/meta-llama/Llama-3.1-8B-Instruct"
        version: 2
        p0: false
