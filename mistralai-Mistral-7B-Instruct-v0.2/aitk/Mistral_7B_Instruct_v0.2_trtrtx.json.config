{
    "name": "Convert to NVIDIA TRT for RTX",
    "oliveFile": "NvTensorRtRtx/Mistral-7B-Instruct-v0.2_model_builder_int4.json",
    "isLLM": true,
    "debugInfo": {
        "autoGenerated": true,
        "useModelBuilder": "mb"
    },
    "needHFLogin": true,
    "runtime": {
        "autoGenerated": true,
        "name": "Evaluate on",
        "type": "enum",
        "displayNames": [
            "NVIDIA TensorRT for RTX"
        ],
        "path": "systems.local_system.accelerators.0.execution_providers.0",
        "values": [
            "NvTensorRTRTXExecutionProvider"
        ],
        "readOnly": false
    },
    "optimizationPaths": [
        {
            "path": "passes.mb.precision"
        }
    ],
    "optimizationDefault": "int4",
    "sections": [
        {
            "autoGenerated": true,
            "name": "Convert",
            "phase": "Conversion",
            "parameters": [],
            "toggle": {
                "autoGenerated": true,
                "name": "Convert to ONNX format",
                "type": "bool",
                "path": "passes.mb",
                "actions": [
                    [],
                    []
                ],
                "readOnly": true
            }
        },
        {
            "autoGenerated": true,
            "name": "Optimization",
            "phase": "Quantization",
            "parameters": [
                {
                    "autoGenerated": true,
                    "name": "Precision",
                    "description": "Precision of model",
                    "type": "enum",
                    "displayNames": [
                        "Int4",
                        "Bf16",
                        "Fp16",
                        "Fp32"
                    ],
                    "displayType": "RadioGroup",
                    "path": "passes.mb.precision",
                    "values": [
                        "int4",
                        "bf16",
                        "fp16",
                        "fp32"
                    ],
                    "template": {
                        "path": "passes.mb.precision",
                        "template": "ModelBuilderPrecision"
                    }
                }
            ],
            "disableToggleGeneration": true,
            "toggle": {
                "autoGenerated": true,
                "name": "Optimize model",
                "type": "bool",
                "path": "passes.mb",
                "actions": [
                    [],
                    []
                ],
                "readOnly": true
            }
        }
    ]
}
