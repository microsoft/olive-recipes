keywords:
    aitk
arch: llama3
recipes:
    - file: "llama3_2_qnn_config.json"
      device: npu
      ep: QNNExecutionProvider
      aitk:
        oliveFile: "../microsoft-Phi-3.5-mini-instruct/QNN/config.json"
    - file: "llama3_2_vitis_ai_config.json"
      device: npu
      ep: VitisAIExecutionProvider
      aitk:
        oliveFile: "VitisAI/Llama-3.2-1B-Instruct_quark_vitisai_llm.json"
        requirements: AMD/Quark_py3.10.17
        evalRuntime: AMDNPU
        isGPUSuggested: true
    - file: "llama3_2_ov_config.json"
      devices:
        - npu
      ep: OpenVINOExecutionProvider
    - file: "llama3_2_ov_gpu_config.json"
      devices:
        - gpu
        - cpu
      ep: OpenVINOExecutionProvider
    - file: "llama3_2_trtrtx_config.json"
      device: gpu
      ep: NvTensorRTRTXExecutionProvider
      aitk:
        oliveFile: "NvTensorRtRtx/Llama-3.2-1B-Instruct_model_builder_fp16.json"
    - file: "llama3_2_dml_config.json"
      device: gpu
      ep: DmlExecutionProvider
aitk:
    modelInfo:
        id: "huggingface/meta-llama/Llama-3.2-1B-Instruct"
        version: 5
        p0: true
