{
    "input_model": {
        "type": "HfModel",
        "model_path": "Qwen/Qwen2.5-1.5B-Instruct"
    },
    "systems": {
        "target_system": {
            "type": "PythonEnvironment",
            "python_environment_path": "/path/to/qnn/env/bin",
            "accelerators": [
                {   "device": "gpu",
                    "execution_providers": [
                        "QNNExecutionProvider"
                    ]
                }
            ]
        }
    },
    "data_configs": [
        {
            "name": "wikitext2_train_joined",
            "type": "HuggingfaceContainer",
            "load_dataset_config": {
                "data_name": "wikitext",
                "subset": "wikitext-2-raw-v1",
                "split": "train"
            },
            "pre_process_data_config": {
                "strategy": "join",
                "add_special_tokens": false,
                "max_seq_len": 4096,
                "max_samples": 128
            }
        },
        {
            "name": "wikitext2_train_act",
            "type": "HuggingfaceContainer",
            "load_dataset_config": {
                "data_name": "wikitext",
                "subset": "wikitext-2-raw-v1",
                "split": "train"
            },
            "pre_process_data_config": {
                "strategy": "line-by-line",
                "add_special_tokens": true,
                "max_samples": 128,
                "max_seq_len": 512
            }
        }
    ],
    "passes": {
        "q": {
            "type": "QuaRot"
        },
        "g": {
            "type": "GptqQuantizer",
            "sym": true,
            "group_size": 32,
            "desc_act": false,
            "data_config": "wikitext2_train_joined"
        },
        "mb": {
            "type": "ModelBuilder",
            "precision": "int4",
            "int4_block_size": 32,
            "int4_accuracy_level": 4,
            "int4_op_types_to_quantize": [
                "MatMul",
                "Gemm"
            ]
        },
        "gs": {
            "type": "GraphSurgeries",
            "surgeries": [
                {
                    "surgeon": "RemoveRopeMultiCache"
                },
                {
                    "surgeon": "AttentionMaskToSequenceLengths"
                }
            ],
            "save_as_external_data": true
        },
        "st": {
            "type": "StaticLLM",
            "batch_size": 1,
            "context_length": 1
        }
    },
    "target": "target_system",
    "log_severity_level": 1,
    "output_dir": "models/qwen_2.5_1.5b_Instruct",
    "cache_dir": "cache",
    "no_artifacts": true,
    "evaluate_input_model": false
}
