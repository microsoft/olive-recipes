# Profiling

## How to use in Playground

If you toggle on "Show resource usage" in the preferences panel, CPU, GPU, NPU and memory usage will be shown together with model's response.

Note that the resource usage is updated once per second, so if the response is quick, the resource usage may not be able to reflect the real usage.

## How to use in Profiling Tab

In start, there are two options:

### Display session usage of "The next session"

When this is selected and started, we will wait until the next started process that emits Windows ML events (see explaination in "Explore more tool") and start to show the resource usage of it.

This option is ideal for testing a run-once app. In this case, you could start profiling and run the app and the resource usages will be shown up.

### Display session usage of "Process Id or Name"

When this is selected and started, we will show resource usage and Windows ML events of the process you speficied.

This option is ideal for moniting a always-run app.

For Process Id or Name, it could be:

- Process Id like 12345
- Process Name like Inference.Service.Agent. The case sensitive name of app without .exe
- Process Path like c:\Users\xxx\Inference.Service.Agent.exe

For Process Name or Process Path, use the first match.


After start, two plots could be active for your app:

### Resource usage plot

This plot shows usage of CPU, GPU, NPU and Memory. The usage will be updated once per second and kept for 10 minutes. To know how it works or need more detailed daa, see "Explore more tool".

### Session plot

In your app emits Windows ML events and VS Code is running in admin mode, we will show captured events here.

Current the event typs are:

#### SessionCreation

This event captures the duration of session creation.

#### Inference

This event captures how each inference runs.

## Explore more tools

There is an overview doc of all related tools for [AI models running locally](https://learn.microsoft.com/en-us/windows/ai/npu-devices/#how-to-measure-performance-of-ai-models-running-locally-on-the-device-npu). We will explain how profiling use them in following sections.

### Performance Counters

Performance counters are used to know the usage of GPU and NPU. For example, a powershell command could be used to show all process usages:

```powershell
Get-Counter -Counter "\GPU Engine(pid_*_*)\Utilization Percentage"
```

There is also an app to help you to capture them [Performance Monitor](https://learn.microsoft.com/en-us/troubleshoot/windows-server/support-tools/troubleshoot-issues-performance-monitor). 

### Windows ML Events

There are a bunch of different events for diagostic in [onnxruntime](https://onnxruntime.ai/docs/performance/tune-performance/logging_tracing.html). So when your app emits any of them, profiling will start to moniter it in "The next session" mode.

Specificaly, the SessionCreation and Inference are generated by events from [telemetry.cc](https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/core/platform/windows/telemetry.cc).

### ETW / WPR / WPA

To capture the event, we could leverage [Microsoft.Diagnostics.Tracing.TraceEvent library](https://github.com/microsoft/perfview/blob/main/documentation/TraceEvent/TraceEventLibrary.md) or WPR.

WPR and WPA are easy-to-use and more powerful tools. You could use them to analyze more detailed resource usage offline. For example, capture a basic CPU, GPU, NPU and Memory usage with command

```
wpr -start CPU.Light -start NeuralProcessing.Light -start VirtualAllocation.Light
```

Save it and open in [WPA](https://apps.microsoft.com/detail/9N58QRW40DFW).

```
wpr -stop test.etl
```
