import json
from pathlib import Path

from .constants import EPNames, OlivePassNames, OlivePropertyNames
from .model_parameter import ModelParameter, OptimizationPath, RuntimeOverwrite
from .utils import open_ex


def create_model_parameter(aitk, name: str, configFile: Path):
    oliveFile = aitk.get("oliveFile")
    requirements = aitk.get("requirements", None)
    runtimeOverwrite = None
    if requirements:
        runtimeOverwrite = RuntimeOverwrite(autoGenerated=True, executeRequirement=requirements)
    aitkRuntimeOverwrite = aitk.get("runtimeOverwrite")
    if aitkRuntimeOverwrite:
        if runtimeOverwrite is None:
            runtimeOverwrite = RuntimeOverwrite(autoGenerated=True)
        executeEp = aitkRuntimeOverwrite.get("executeEp")
        runtimeOverwrite.executeEp = EPNames(executeEp)

    requirements_patches = aitk.get("requirementsPatches")
    evalRuntime = aitk.get("evalRuntime")

    parameter = ModelParameter(
        name=name,
        oliveFile=oliveFile,
        runtimeOverwrite=runtimeOverwrite,
        executeRuntimeFeatures=requirements_patches,
        evalRuntime=evalRuntime,
        optimizationPaths=[],
    )
    parameter._file = str(configFile) + ".config"
    return parameter


def set_optimization_path(parameter: ModelParameter, configFile: str):
    parameter.optimizationPaths = []
    with open_ex(configFile, "r") as f:
        content = json.load(f)
    for k, v in content[OlivePropertyNames.Passes].items():
        vType = v[OlivePropertyNames.Type].lower()
        if vType == OlivePassNames.OrtTransformersOptimization:
            float16 = v.get(OlivePropertyNames.Float16)
            if float16 is not None:
                parameter.optimizationPaths.append(
                    OptimizationPath(
                        name="fp16",
                        path=f"{OlivePropertyNames.Passes}.{k}.{OlivePropertyNames.Float16}",
                    )
                )
                return
        elif vType == OlivePassNames.OpenVINOQuantization:
            # TODO it is not specified, default 8 bit https://docs.openvino.ai/2025/openvino-workflow/model-optimization-guide/quantizing-models-post-training/basic-quantization-flow.html#quantize-a-model
            parameter.optimizationPaths.append(
                OptimizationPath(
                    name="int8",
                    path=f"{OlivePropertyNames.Passes}.{k}",
                )
            )
            return
        elif vType in [
            OlivePassNames.OnnxQuantization,
            OlivePassNames.OnnxStaticQuantization,
            OlivePassNames.OnnxDynamicQuantization,
        ]:
            parameter.optimizationPaths.append(
                OptimizationPath(
                    name="WeightType",
                    path=f"{OlivePropertyNames.Passes}.{k}.{OlivePropertyNames.Precision}",
                )
            )
            parameter.optimizationPaths.append(
                OptimizationPath(
                    name="ActivationType",
                    path=f"{OlivePropertyNames.Passes}.{k}.{OlivePropertyNames.ActivationType}",
                )
            )
            return
        elif vType == OlivePassNames.OnnxFloatToFloat16:
            parameter.optimizationPaths.append(
                OptimizationPath(
                    name="fp16",
                    path=f"{OlivePropertyNames.Passes}.{k}",
                )
            )
            return
