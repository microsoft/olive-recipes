import json
from pathlib import Path
from typing import Optional

from .constants import OliveDeviceTypes, OlivePassNames, OlivePropertyNames, PhaseTypeEnum
from .model_parameter import ModelParameter, Section
from .parameters import Parameter
from .utils import open_ex


def generate_quantization_config(folder: Path, file: str) -> Optional[Section]:
    """
    Generates a quantization configuration section for the given file.
    """
    with open_ex(folder / file, "r") as f:
        content = json.load(f)
    parameters = []
    for k, v in content[OlivePropertyNames.Passes].items():
        if v[OlivePropertyNames.Type].lower() == OlivePassNames.OpenVINOOptimumConversion:
            config = v.get("ov_quant_config", {})
            dataset = config.get("dataset")
            if dataset:
                parameters.append(
                    Parameter(
                        template=Parameter(
                            autoGenerated=True,
                            template="QuantizationDataset",
                            path=f"{OlivePropertyNames.Passes}.{k}.ov_quant_config.dataset",
                            values=[dataset],
                        )
                    )
                )
    if parameters:
        return Section(
            autoGenerated=True,
            name="Quantize",
            phase=PhaseTypeEnum.Quantization,
            parameters=parameters,
        )
    return None


def isLLM_by_id(id: str) -> bool:
    check_list = ["deepseek-ai/DeepSeek", "meta-llama/Llama", "microsoft/Phi", "mistralai/Mistral", "Qwen/Qwen"]
    return any(check in id for check in check_list)


def generator_intel(id: str, recipe, folder: Path):
    aitk = recipe.get("aitk", {})
    auto = aitk.get("auto", True)
    isLLM = aitk.get("isLLM", isLLM_by_id(id))
    if not auto or not isLLM:
        return
    intel_runtime_values: list[str] = recipe.get("devices", [recipe.get("device")])
    file = recipe.get("file")

    name = f"Convert to Intel {"/".join([runtime.upper() for runtime in intel_runtime_values])}"
    addCpu = False
    oliveFile = aitk.get("oliveFile")

    sections = []
    quantize = generate_quantization_config(folder, file)
    if quantize:
        sections.append(quantize)

    parameter = ModelParameter(
        name=name,
        isLLM=isLLM,
        isIntel=True,
        intelRuntimeValues=[OliveDeviceTypes(runtime) for runtime in intel_runtime_values],
        addCpu=addCpu,
        oliveFile=oliveFile,
        sections=sections,
    )
    parameter._file = str(folder / (file + ".config"))
    parameter.writeIfChanged()
    print(f"\tGenerated Intel configuration for {file}")
