import json
from pathlib import Path
from typing import Optional

from .constants import OliveDeviceTypes, OlivePassNames, OlivePropertyNames, PhaseTypeEnum
from .generator_common import create_model_parameter, set_optimization_path
from .model_parameter import ModelParameter, OptimizationPath, Section
from .parameters import Parameter
from .utils import isLLM_by_id, open_ex


def generate_quantization_config(configFile: Path, parameter: ModelParameter) -> Optional[Section]:
    """
    Generates a quantization configuration section for the given file.
    """
    with open_ex(configFile, "r") as f:
        content = json.load(f)
    parameters = []
    for k, v in content[OlivePropertyNames.Passes].items():
        if v[OlivePropertyNames.Type].lower() == OlivePassNames.OpenVINOOptimumConversion:
            config = v.get(OlivePropertyNames.OvQuantConfig, {})
            weight_format = config.get(OlivePropertyNames.WeightFormat)
            if weight_format:
                path = f"{OlivePropertyNames.Passes}.{k}.{OlivePropertyNames.OvQuantConfig}.{OlivePropertyNames.WeightFormat}"
                # TODO currently only one option so not adding
                # parameters.append(
                #     Parameter(
                #         autoGenerated=True,
                #         template=Parameter(
                #             template="WeightTypeIntel",
                #             path=path,
                #         ),
                #     )
                # )
                parameter.optimizationPaths.append(
                    OptimizationPath(
                        path=path,
                    )
                )

            dataset = config.get(OlivePropertyNames.Dataset)
            if dataset:
                parameters.append(
                    Parameter(
                        autoGenerated=True,
                        template=Parameter(
                            template="QuantizationDataset",
                            path=f"{OlivePropertyNames.Passes}.{k}.{OlivePropertyNames.OvQuantConfig}.{OlivePropertyNames.Dataset}",
                            values=[dataset],
                        ),
                    )
                )
    if parameters:
        return Section(
            autoGenerated=True,
            name="Quantize",
            phase=PhaseTypeEnum.Quantization,
            parameters=parameters,
        )
    return None


def generator_intel(id: str, recipe, folder: Path):
    aitk = recipe.get("aitk", {})
    auto = aitk.get("auto", True)
    if not auto:
        return

    isLLM = isLLM_by_id(id)
    file = recipe.get("file")
    configFile = folder / file

    if not isLLM:
        modelParameter = ModelParameter.Read(str(configFile) + ".config")
        set_optimization_path(modelParameter, str(configFile))
        modelParameter.writeIfChanged()
        return

    intel_runtime_values: list[str] = recipe.get("devices", [recipe.get("device")])
    name = f"Convert to Intel {"/".join([runtime.upper() for runtime in intel_runtime_values])}"

    parameter = create_model_parameter(aitk, name, configFile)
    parameter.isLLM = isLLM

    parameter.intelRuntimeValues = [OliveDeviceTypes(runtime) for runtime in intel_runtime_values]
    parameter.isIntel = True

    quantize = generate_quantization_config(configFile, parameter)
    if quantize:
        parameter.sections.append(quantize)

    parameter.writeIfChanged()
    print(f"\tGenerated Intel configuration for {file}")
