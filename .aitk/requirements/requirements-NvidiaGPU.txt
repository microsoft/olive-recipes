--extra-index-url https://download.pytorch.org/whl/cu128
# torch==2.7.0+cu128
torch==2.7.0+cu128
filelock==3.18.0
fsspec==2024.12.0
jinja2==3.1.6
networkx==3.4.2
sympy==1.13.3
typing-extensions==4.13.2
# onnx==1.17.0
onnx==1.17.0
numpy==2.2.4
protobuf==3.20.3
# olive-ai@git+https://github.com/microsoft/Olive.git@8ff071c0ae9b1c38c0619ee72e8cb031957c63c4#egg=olive-ai
olive-ai@git+https://github.com/microsoft/Olive.git@8ff071c0ae9b1c38c0619ee72e8cb031957c63c4#egg=olive-ai
onnx-ir==0.1.5
onnxscript==0.3.2
optuna==4.3.0
pandas==2.2.3
pydantic==2.11.3
pyyaml==6.0.2
torchmetrics==1.7.1
transformers==4.51.3
# tabulate==0.9.0
tabulate==0.9.0
# datasets==3.5.0
datasets==3.5.0
aiohttp==3.11.16
dill==0.3.8
huggingface-hub[hf_xet]==0.34.4
multiprocess==0.70.16
packaging==24.2
pyarrow==19.0.1
requests==2.32.3
tqdm==4.67.1
xxhash==3.5.0
# ipykernel==6.29.5
ipykernel==6.29.5
comm==0.2.2
debugpy==1.8.14
ipython==8.35.0
jupyter-client==8.6.3
jupyter-core==5.7.2
matplotlib-inline==0.1.7
nest-asyncio==1.6.0
psutil==7.0.0
pyzmq==26.4.0
tornado==6.4.2
traitlets==5.14.3
# ipywidgets==8.1.5
ipywidgets==8.1.5
jupyterlab-widgets==3.0.14
widgetsnbextension==4.0.14
# torchvision==0.22.0+cu128
torchvision==0.22.0+cu128
pillow==11.2.1
# onnxruntime-gpu==1.21.0
onnxruntime-gpu==1.21.0
coloredlogs==15.0.1
flatbuffers==25.2.10
# 0.8.X is not working for DML LLM because
# File "onnxruntime_genai\models\builder.py", line 571, in make_tensor_proto_from_tensor
#    data_type=self.to_onnx_dtype[tensor.dtype],
#KeyError: torch.uint8
# onnxruntime-genai-cuda==0.7.0
onnxruntime-genai-cuda==0.7.0
# optimum==1.26.0
optimum==1.26.0
