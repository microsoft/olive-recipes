"""
Script to update genai_config.json generated by model builder
to add vision and embedding sections for Qwen2.5-VL models.

Also supports combining all models into a single directory.
"""

import argparse
import json
import shutil
from pathlib import Path


def update_genai_config(
    config_path: str,
    vision_model: str = "vision.onnx",
    embedding_model: str = "embedding.onnx",
    decoder_model: str = None,
    output_path: str = None,
):
    """
    Update genai_config.json with vision and embedding sections.
    """
    config_path = Path(config_path)

    with open(config_path, 'r') as f:
        config = json.load(f)

    model = config.get("model", {})

    # Update model type
    model["type"] = "qwen2_5_vl"

    # Add vision token IDs (Qwen2.5-VL specific)
    model["image_token_id"] = 151655
    model["video_token_id"] = 151656
    model["vision_start_token_id"] = 151652

    # Update decoder filename if provided
    if decoder_model and "decoder" in model:
        model["decoder"]["filename"] = decoder_model

    # Add embedding section
    model["embedding"] = {
        "filename": embedding_model,
        "inputs": {
            "input_ids": "input_ids",
            "image_features": "image_features"
        },
        "outputs": {
            "inputs_embeds": "inputs_embeds"
        },
        "session_options": {
            "log_id": "onnxruntime-genai",
            "provider_options": []
        }
    }

    # Add vision section
    model["vision"] = {
        "filename": vision_model,
        "spatial_merge_size": 2,
        "tokens_per_second": 2.0,
        "inputs": {
            "pixel_values": "pixel_values",
            "image_grid_thw": "image_grid_thw"
        },
        "outputs": {
            "image_features": "image_features"
        },
        "session_options": {
            "log_id": "onnxruntime-genai",
            "provider_options": []
        }
    }

    config["model"] = model

    # Fix search options - replace entire section with valid defaults
    config["search"] = {
        "diversity_penalty": 0.0,
        "do_sample": False,
        "early_stopping": True,
        "length_penalty": 1.0,
        "max_length": 4096,
        "min_length": 0,
        "no_repeat_ngram_size": 0,
        "num_beams": 1,
        "num_return_sequences": 1,
        "past_present_share_buffer": True,
        "repetition_penalty": 1.0,
        "temperature": 1.0,
        "top_k": 50,
        "top_p": 1.0,
    }
    print("Fixed search options")

    output = Path(output_path) if output_path else config_path
    with open(output, 'w') as f:
        json.dump(config, f, indent=4)

    print(f"Updated config saved to: {output}")
    return config


def combine_models(
    text_dir: str = "models/text",
    embedding_dir: str = "models/embedding",
    vision_dir: str = "models/vision",
    output_dir: str = "models/combined",
):
    """
    Combine all models into a single directory and update genai_config.json.
    """
    text_path = Path(text_dir)
    embedding_path = Path(embedding_dir)
    vision_path = Path(vision_dir)
    output_path = Path(output_dir)

    # Create output directory
    output_path.mkdir(parents=True, exist_ok=True)

    # Copy decoder model and config
    decoder_onnx = text_path / "model.onnx"
    if decoder_onnx.exists():
        shutil.copy(decoder_onnx, output_path / "decoder.onnx")
        print(f"Copied decoder: {decoder_onnx} -> {output_path / 'decoder.onnx'}")

    # Copy genai_config.json
    config_file = text_path / "genai_config.json"
    if config_file.exists():
        shutil.copy(config_file, output_path / "genai_config.json")
        print(f"Copied config: {config_file}")

    # Copy tokenizer files
    for pattern in ["tokenizer*", "*.json", "*.model", "*.tiktoken"]:
        for f in text_path.glob(pattern):
            if f.name != "genai_config.json":
                shutil.copy(f, output_path / f.name)
                print(f"Copied: {f.name}")

    # Copy embedding model
    embedding_onnx = embedding_path / "model.onnx"
    if embedding_onnx.exists():
        shutil.copy(embedding_onnx, output_path / "embedding.onnx")
        print(f"Copied embedding: {embedding_onnx} -> {output_path / 'embedding.onnx'}")

    # Copy vision model
    vision_onnx = vision_path / "model.onnx"
    if vision_onnx.exists():
        shutil.copy(vision_onnx, output_path / "vision.onnx")
        print(f"Copied vision: {vision_onnx} -> {output_path / 'vision.onnx'}")

    # Update genai_config.json
    output_config = output_path / "genai_config.json"
    if output_config.exists():
        update_genai_config(
            config_path=str(output_config),
            vision_model="vision.onnx",
            embedding_model="embedding.onnx",
            decoder_model="decoder.onnx",
        )

    print(f"\nAll models combined in: {output_path}")
    print("\nTo run inference:")
    print(f"  python vl_inference.py --model_path {output_path} --image cat.jpg --prompt 'Describe this image'")


def main():
    parser = argparse.ArgumentParser(
        description="Update genai_config.json for Qwen2.5-VL multimodal inference"
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # Update command
    update_parser = subparsers.add_parser("update", help="Update existing genai_config.json")
    update_parser.add_argument("--config", type=str, required=True, help="Path to existing genai_config.json")
    update_parser.add_argument("--vision_model", type=str, default="vision.onnx", help="Vision model filename")
    update_parser.add_argument("--embedding_model", type=str, default="embedding.onnx", help="Embedding model filename")
    update_parser.add_argument("--decoder_model", type=str, default=None, help="Decoder model filename")
    update_parser.add_argument("--output", type=str, default=None, help="Output path")

    # Combine command
    combine_parser = subparsers.add_parser("combine", help="Combine all models into one directory")
    combine_parser.add_argument("--text_dir", type=str, default="models/text", help="Text/decoder model directory")
    combine_parser.add_argument("--embedding_dir", type=str, default="models/embedding", help="Embedding model directory")
    combine_parser.add_argument("--vision_dir", type=str, default="models/vision", help="Vision model directory")
    combine_parser.add_argument("--output_dir", type=str, default="models/combined", help="Output directory")

    args = parser.parse_args()

    if args.command == "update":
        update_genai_config(
            config_path=args.config,
            vision_model=args.vision_model,
            embedding_model=args.embedding_model,
            decoder_model=args.decoder_model,
            output_path=args.output,
        )
    elif args.command == "combine":
        combine_models(
            text_dir=args.text_dir,
            embedding_dir=args.embedding_dir,
            vision_dir=args.vision_dir,
            output_dir=args.output_dir,
        )
    else:
        # Default: combine with default paths
        combine_models()


if __name__ == "__main__":
    main()
